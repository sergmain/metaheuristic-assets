snippets:
  - code: simple-metrics.fit:1.2
    type: fit
    env: python-3
    sourcing: station
    metas:
      - key: task-params-version
        value: 2
      - key: snippet-params-as-file
        value: true
      - key: snippet-params-file-ext
        value: .py
    params: |+
      import gc
      import os
      import sys

      import yaml
      from datetime import datetime

      from keras import backend as K


      class Logger(object):
          def __init__(self, artifact_path):
              self.terminal = sys.stdout
              self.log = open(os.path.join(artifact_path, "logfile-fit.log"), "w")

          def write(self, message):
              self.terminal.write(message)
              self.log.write(message)
              self.log.flush()

          def flush(self):
              # this flush method is needed for python 3 compatibility.
              # this handles the flush command by doing nothing.
              # you might want to specify some extra behavior here.
              pass


      print(sys.argv)
      cwd = os.getcwd()

      artifact_path = os.path.join(cwd, 'artifacts')
      sys.stdout = Logger(artifact_path)

      yaml_file = os.path.join(artifact_path, 'params-v2.yaml')

      with open(yaml_file, 'r') as stream:
          params = (yaml.load(stream))['taskYaml']


      output_file_path = params['outputResourceAbsolutePath']
      with open(output_file_path, 'w') as output_file:
          output_file.write("Ok")
          output_file.close()


      print(params['hyperParams'])
      print('Done.')
      print(str(datetime.now()))

      K.clear_session()
      gc.collect()

  - code: simple-metrics.predict:1.2
    type: predict
    env: python-3
    sourcing: station
    metrics: true
    metas:
      - key: task-params-version
        value: 2
      - key: snippet-params-as-file
        value: true
      - key: snippet-params-file-ext
        value: .py
    params: |+
      import gc
      import os
      import sys
      from random import randint

      import yaml
      from datetime import datetime
      from keras import backend as K


      class Logger(object):
          def __init__(self, artifact_path):
              self.terminal = sys.stdout
              self.log = open(os.path.join(artifact_path, "logfile-predict.log"), "w")

          def write(self, message):
              self.terminal.write(message)
              self.log.write(message)
              self.log.flush()

          def flush(self):
              # this flush method is needed for python 3 compatibility.
              # this handles the flush command by doing nothing.
              # you might want to specify some extra behavior here.
              pass


      print(sys.argv)
      cwd = os.getcwd()

      artifact_path = os.path.join(cwd, 'artifacts')
      sys.stdout = Logger(artifact_path)

      yaml_file = os.path.join(artifact_path, 'params-v2.yaml')

      with open(yaml_file, 'r') as stream:
          params = (yaml.load(stream))['taskYaml']

      print(params['hyperParams'])

      output_file_path = params['outputResourceAbsolutePath']
      with open(output_file_path, 'w') as output_file:
          output_file.write("Ok")
          output_file.close()

      print(str(datetime.now()))


      metrics = {}
      metricValues = {}
      metrics['values'] = metricValues

      metricValues['sum'] = randint(100, 200)
      metrics_yaml_file = os.path.join(artifact_path, 'metrics.yaml')

      with open(metrics_yaml_file, 'w') as outfile:
          yaml.dump(metrics, outfile, default_flow_style=False)


      K.clear_session()
      gc.collect()

